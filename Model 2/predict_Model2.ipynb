{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "pd.set_option(\"display.max_rows\", 500, \"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>Q11A</th>\n",
       "      <th>Q12A</th>\n",
       "      <th>Q13A</th>\n",
       "      <th>Q14A</th>\n",
       "      <th>Q15A</th>\n",
       "      <th>Q16A</th>\n",
       "      <th>Q17A</th>\n",
       "      <th>Q18A</th>\n",
       "      <th>Q19A</th>\n",
       "      <th>Q20A</th>\n",
       "      <th>Q21A</th>\n",
       "      <th>Q22A</th>\n",
       "      <th>Q23A</th>\n",
       "      <th>Q24A</th>\n",
       "      <th>Q25A</th>\n",
       "      <th>Q26A</th>\n",
       "      <th>Q27A</th>\n",
       "      <th>Q28A</th>\n",
       "      <th>Q29A</th>\n",
       "      <th>Q30A</th>\n",
       "      <th>Q31A</th>\n",
       "      <th>Q32A</th>\n",
       "      <th>Q33A</th>\n",
       "      <th>Q34A</th>\n",
       "      <th>Q35A</th>\n",
       "      <th>Q36A</th>\n",
       "      <th>Q37A</th>\n",
       "      <th>Q38A</th>\n",
       "      <th>Q39A</th>\n",
       "      <th>Q40A</th>\n",
       "      <th>Q41A</th>\n",
       "      <th>Q42A</th>\n",
       "      <th>Q43A</th>\n",
       "      <th>Q44A</th>\n",
       "      <th>Q45A</th>\n",
       "      <th>Q46A</th>\n",
       "      <th>Q47A</th>\n",
       "      <th>Q48A</th>\n",
       "      <th>Q49A</th>\n",
       "      <th>Q50A</th>\n",
       "      <th>Q51A</th>\n",
       "      <th>Q52A</th>\n",
       "      <th>Q53A</th>\n",
       "      <th>Q54A</th>\n",
       "      <th>Q55A</th>\n",
       "      <th>Q56A</th>\n",
       "      <th>Q57A</th>\n",
       "      <th>Q58A</th>\n",
       "      <th>Q59A</th>\n",
       "      <th>Q60A</th>\n",
       "      <th>Q61A</th>\n",
       "      <th>Q62A</th>\n",
       "      <th>Q63A</th>\n",
       "      <th>Q64A</th>\n",
       "      <th>Q65A</th>\n",
       "      <th>Q66A</th>\n",
       "      <th>Q67A</th>\n",
       "      <th>Q68A</th>\n",
       "      <th>Q69A</th>\n",
       "      <th>Q70A</th>\n",
       "      <th>Q71A</th>\n",
       "      <th>Q72A</th>\n",
       "      <th>Q73A</th>\n",
       "      <th>Q74A</th>\n",
       "      <th>Q75A</th>\n",
       "      <th>Q76A</th>\n",
       "      <th>Q77A</th>\n",
       "      <th>Q78A</th>\n",
       "      <th>Q79A</th>\n",
       "      <th>Q80A</th>\n",
       "      <th>Q81A</th>\n",
       "      <th>Q82A</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>Q92A</th>\n",
       "      <th>Q93A</th>\n",
       "      <th>Q94A</th>\n",
       "      <th>Q95A</th>\n",
       "      <th>Q96A</th>\n",
       "      <th>Q97A</th>\n",
       "      <th>Q98A</th>\n",
       "      <th>Q99A</th>\n",
       "      <th>Q100A</th>\n",
       "      <th>Q101A</th>\n",
       "      <th>Q102A</th>\n",
       "      <th>Q103A</th>\n",
       "      <th>Q104A</th>\n",
       "      <th>Q105A</th>\n",
       "      <th>Q106A</th>\n",
       "      <th>Q107A</th>\n",
       "      <th>Q108A</th>\n",
       "      <th>Q109A</th>\n",
       "      <th>Q110A</th>\n",
       "      <th>Q111A</th>\n",
       "      <th>Q112A</th>\n",
       "      <th>Q113A</th>\n",
       "      <th>Q114A</th>\n",
       "      <th>Q115A</th>\n",
       "      <th>Q116A</th>\n",
       "      <th>Q117A</th>\n",
       "      <th>Q118A</th>\n",
       "      <th>Q119A</th>\n",
       "      <th>Q120A</th>\n",
       "      <th>Q121A</th>\n",
       "      <th>Q122A</th>\n",
       "      <th>Q123A</th>\n",
       "      <th>Q124A</th>\n",
       "      <th>Q125A</th>\n",
       "      <th>Q126A</th>\n",
       "      <th>Q127A</th>\n",
       "      <th>Q128A</th>\n",
       "      <th>Q129A</th>\n",
       "      <th>Q130A</th>\n",
       "      <th>Q131A</th>\n",
       "      <th>Q132A</th>\n",
       "      <th>Q133A</th>\n",
       "      <th>Q134A</th>\n",
       "      <th>Q135A</th>\n",
       "      <th>Q136A</th>\n",
       "      <th>Q137A</th>\n",
       "      <th>Q138A</th>\n",
       "      <th>Q139A</th>\n",
       "      <th>Q140A</th>\n",
       "      <th>Q141A</th>\n",
       "      <th>Q142A</th>\n",
       "      <th>Q143A</th>\n",
       "      <th>Q144A</th>\n",
       "      <th>Q145A</th>\n",
       "      <th>Q146A</th>\n",
       "      <th>Q147A</th>\n",
       "      <th>Q148A</th>\n",
       "      <th>Q149A</th>\n",
       "      <th>Q150A</th>\n",
       "      <th>Q151A</th>\n",
       "      <th>Q152A</th>\n",
       "      <th>Q153A</th>\n",
       "      <th>Q154A</th>\n",
       "      <th>Q155A</th>\n",
       "      <th>Q156A</th>\n",
       "      <th>Q157A</th>\n",
       "      <th>Q158A</th>\n",
       "      <th>Q159A</th>\n",
       "      <th>Q160A</th>\n",
       "      <th>Q161A</th>\n",
       "      <th>Q162A</th>\n",
       "      <th>Q163A</th>\n",
       "      <th>Q164A</th>\n",
       "      <th>Q165A</th>\n",
       "      <th>Q166A</th>\n",
       "      <th>Q167A</th>\n",
       "      <th>Q168A</th>\n",
       "      <th>Q169A</th>\n",
       "      <th>Q170A</th>\n",
       "      <th>Q171A</th>\n",
       "      <th>Q172A</th>\n",
       "      <th>Q173A</th>\n",
       "      <th>Q174A</th>\n",
       "      <th>Q175A</th>\n",
       "      <th>Q176A</th>\n",
       "      <th>Q177A</th>\n",
       "      <th>Q178A</th>\n",
       "      <th>Q179A</th>\n",
       "      <th>Q180A</th>\n",
       "      <th>Q181A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  Q11A  Q12A  Q13A  Q14A  \\\n",
       "0    5    2    1    2    5    2    4    4    2     4     2     4     6     3   \n",
       "\n",
       "   Q15A  Q16A  Q17A  Q18A  Q19A  Q20A  Q21A  Q22A  Q23A  Q24A  Q25A  Q26A  \\\n",
       "0     1     6     2     1     4     1     7     1     4     5     2     2   \n",
       "\n",
       "   Q27A  Q28A  Q29A  Q30A  Q31A  Q32A  Q33A  Q34A  Q35A  Q36A  Q37A  Q38A  \\\n",
       "0     5     2     3     7     7     2     2     4     2     1     7     1   \n",
       "\n",
       "   Q39A  Q40A  Q41A  Q42A  Q43A  Q44A  Q45A  Q46A  Q47A  Q48A  Q49A  Q50A  \\\n",
       "0     3     2     7     6     2     2     6     2     6     4     5     3   \n",
       "\n",
       "   Q51A  Q52A  Q53A  Q54A  Q55A  Q56A  Q57A  Q58A  Q59A  Q60A  Q61A  Q62A  \\\n",
       "0     3     2     2     2     2     4     5     3     3     4     6     4   \n",
       "\n",
       "   Q63A  Q64A  Q65A  Q66A  Q67A  Q68A  Q69A  Q70A  Q71A  Q72A  Q73A  Q74A  \\\n",
       "0     6     3     2     2     7     2     2     4     4     5     1     2   \n",
       "\n",
       "   Q75A  Q76A  Q77A  Q78A  Q79A  Q80A  Q81A  Q82A  Q83A  Q84A  Q85A  Q86A  \\\n",
       "0     2     4     6     2     6     3     5     2     3     6     7     2   \n",
       "\n",
       "   Q87A  Q88A  Q89A  Q90A  Q91A  Q92A  Q93A  Q94A  Q95A  Q96A  Q97A  Q98A  \\\n",
       "0     4     1     2     2     5     2     6     2     6     7     2     2   \n",
       "\n",
       "   Q99A  Q100A  Q101A  Q102A  Q103A  Q104A  Q105A  Q106A  Q107A  Q108A  Q109A  \\\n",
       "0     1      4      2      7      6      6      2      2      6      2      7   \n",
       "\n",
       "   Q110A  Q111A  Q112A  Q113A  Q114A  Q115A  Q116A  Q117A  Q118A  Q119A  \\\n",
       "0      1      3      6      7      2      7      3      4      2      2   \n",
       "\n",
       "   Q120A  Q121A  Q122A  Q123A  Q124A  Q125A  Q126A  Q127A  Q128A  Q129A  \\\n",
       "0      1      6      6      2      1      3      6      2      2      6   \n",
       "\n",
       "   Q130A  Q131A  Q132A  Q133A  Q134A  Q135A  Q136A  Q137A  Q138A  Q139A  \\\n",
       "0      2      6      5      2      5      6      2      2      2      2   \n",
       "\n",
       "   Q140A  Q141A  Q142A  Q143A  Q144A  Q145A  Q146A  Q147A  Q148A  Q149A  \\\n",
       "0      6      5      7      6      3      6      2      3      3      2   \n",
       "\n",
       "   Q150A  Q151A  Q152A  Q153A  Q154A  Q155A  Q156A  Q157A  Q158A  Q159A  \\\n",
       "0      1      2      6      1      2      6      4      1      4      6   \n",
       "\n",
       "   Q160A  Q161A  Q162A  Q163A  Q164A  Q165A  Q166A  Q167A  Q168A  Q169A  \\\n",
       "0      6      4      4      2      1      2      3      4      7      2   \n",
       "\n",
       "   Q170A  Q171A  Q172A  Q173A  Q174A  Q175A  Q176A  Q177A  Q178A  Q179A  \\\n",
       "0      1      7      2      4      2      6      7      6      1      1   \n",
       "\n",
       "   Q180A  Q181A  \n",
       "0      3      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traits = [\"Openness\", \"Agreeableness\", \"Persistence\", \"Cooperativeness\", \"Openness to Experience\", \"Adjustment\", \"Ambition\", \"Learning Approach\"]\n",
    "questions_dict = {'Openness': ['Q7A', 'Q19A', 'Q26A', 'Q27A', 'Q59A', 'Q75A', 'Q76A', 'Q84A', 'Q94A', 'Q100A', 'Q115A', 'Q138A', 'Q139A', 'Q150A', 'Q153A', 'Q161A'], 'Agreeableness': ['Q8A', 'Q9A', 'Q11A', 'Q12A', 'Q16A', 'Q19A', 'Q23A', 'Q24A', 'Q32A', 'Q34A', 'Q40A', 'Q46A', 'Q50A', 'Q51A', 'Q52A', 'Q62A', 'Q65A', 'Q77A', 'Q80A', 'Q86A', 'Q87A', 'Q97A', 'Q104A', 'Q111A', 'Q118A', 'Q119A', 'Q123A', 'Q129A', 'Q130A', 'Q172A', 'Q181A'], 'Persistence': ['Q4A', 'Q5A', 'Q13A', 'Q14A', 'Q22A', 'Q25A', 'Q31A', 'Q48A', 'Q81A', 'Q101A', 'Q110A', 'Q116A', 'Q137A', 'Q141A', 'Q144A', 'Q145A', 'Q152A', 'Q167A'], 'Cooperativeness': ['Q6A', 'Q8A', 'Q9A', 'Q10A', 'Q11A', 'Q12A', 'Q19A', 'Q23A', 'Q24A', 'Q34A', 'Q40A', 'Q50A', 'Q51A', 'Q52A', 'Q62A', 'Q65A', 'Q77A', 'Q80A', 'Q85A', 'Q97A', 'Q111A', 'Q114A', 'Q117A', 'Q123A', 'Q166A', 'Q172A'], 'Openness to Experience': ['Q7A', 'Q26A', 'Q27A', 'Q28A', 'Q43A', 'Q68A', 'Q75A', 'Q83A', 'Q84A', 'Q94A', 'Q100A', 'Q115A', 'Q138A', 'Q139A', 'Q154A', 'Q161A'], 'Adjustment': ['Q1A', 'Q8A', 'Q22A', 'Q24A', 'Q29A', 'Q31A', 'Q33A', 'Q34A', 'Q49A', 'Q57A', 'Q60A', 'Q62A', 'Q71A', 'Q96A', 'Q117A', 'Q123A', 'Q125A', 'Q129A', 'Q134A', 'Q136A', 'Q147A', 'Q148A', 'Q160A', 'Q162A', 'Q173A', 'Q175A', 'Q180A'], 'Ambition': ['Q1A', 'Q4A', 'Q6A', 'Q21A', 'Q22A', 'Q29A', 'Q30A', 'Q31A', 'Q33A', 'Q38A', 'Q49A', 'Q57A', 'Q71A', 'Q72A', 'Q88A', 'Q89A', 'Q96A', 'Q99A', 'Q101A', 'Q116A', 'Q117A', 'Q118A', 'Q123A', 'Q134A', 'Q145A', 'Q147A', 'Q152A', 'Q157A', 'Q160A', 'Q162A', 'Q163A', 'Q164A', 'Q175A'], 'Learning Approach': ['Q55A', 'Q58A', 'Q67A', 'Q68A', 'Q69A', 'Q106A', 'Q107A', 'Q110A']}\n",
    "tp = pd.read_excel('temp.xlsx')\n",
    "# tp = pd.read_csv('questions.csv')\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.892868]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Openness\"\n",
    "\n",
    "model_Openness = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Openness = model_Openness.predict(x)\n",
    "\n",
    "y_pred_Openness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51.041485]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Cooperativeness\"\n",
    "\n",
    "model_Cooperativeness = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Cooperativeness = model_Cooperativeness.predict(x)\n",
    "\n",
    "y_pred_Cooperativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51.927986]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Adjustment\"\n",
    "\n",
    "model_Adjustment = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Adjustment = model_Adjustment.predict(x)\n",
    "\n",
    "y_pred_Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.730444]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Persistence\"\n",
    "\n",
    "model_Persistence = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Persistence = model_Persistence.predict(x)\n",
    "\n",
    "y_pred_Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002630CE7C0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[69.3545]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Agreeableness\"\n",
    "\n",
    "model_Agreeableness = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Agreeableness = model_Agreeableness.predict(x)\n",
    "\n",
    "y_pred_Agreeableness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002630CDEA430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[23.950094]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Ambition\"\n",
    "\n",
    "model_Ambition = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Ambition = model_Ambition.predict(x)\n",
    "\n",
    "y_pred_Ambition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.372784]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Openness to Experience\"\n",
    "\n",
    "model_Openness_to_Experience = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Openness_to_Experience = model_Openness_to_Experience.predict(x)\n",
    "\n",
    "y_pred_Openness_to_Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.0968194]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait = \"Learning Approach\"\n",
    "\n",
    "model_Learning_Approach = tf.keras.models.load_model(trait + '.h5')\n",
    "\n",
    "selected_df = tp[questions_dict[trait]]\n",
    "x = selected_df.to_numpy()\n",
    "\n",
    "y_pred_Learning_Approach = model_Learning_Approach.predict(x)\n",
    "\n",
    "y_pred_Learning_Approach"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96a5b2c8615b6af4330dccc0a175f9e1be44a5aebebe076415aefa8805d772c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
